{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'C:\\\\Users\\\\mtoc1\\\\Documents\\\\github\\\\definitely3people\\\\part3\\\\utils.py'>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "import importlib\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonnets = utils.load_sonnets()\n",
    "sequences, lengths, word_library, feat_library, num_features = utils.vectorize_sonnets(sonnets)\n",
    "sequences = np.array([sequences]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "num_hidden_states = 6\n",
    "\n",
    "model = hmm.MultinomialHMM(n_components=num_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(sequences, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slandering show her will meet parts day \n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_seq, new_hidden_states = model.sample(150)\n",
    "new_sonnet = utils.sequence_to_sonnet(new_seq, feat_library)\n",
    "utils.print_sonnet(new_sonnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wherefore_art_thou_Romeo(num_hidden_states):\n",
    "    np.random.seed(42)\n",
    "    model = hmm.MultinomialHMM(n_components=num_hidden_states)\n",
    "    model = model.fit(sequences, lengths)\n",
    "    return model\n",
    "\n",
    "def serenade_me_oh_sonneteer(model, feat_library):\n",
    "    new_seq, new_hidden_states = model.sample(300) # Words after \\end will be ignored\n",
    "    new_sonnet = utils.sequence_to_sonnet(new_seq, feat_library)\n",
    "    utils.print_sonnet(new_sonnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Testing with 2 hidden states ----\n",
      "[] 1\n",
      "[] 1\n",
      "[] 1\n",
      "[] 1\n",
      "[] 1\n",
      "[] 1\n",
      "[] 1\n",
      "[] 1\n",
      "[] 1\n",
      "[] 1\n",
      "[] 1\n",
      "[] 1\n",
      "[] 1\n",
      "[] 1\n",
      "\n",
      "\n",
      "---- Testing with 5 hidden states ----\n",
      "['pluck'] 14\n",
      "['pluck'] 14\n",
      "['pluck'] 14\n",
      "['pluck'] 14\n",
      "['pluck'] 14\n",
      "['pluck'] 14\n",
      "['pluck'] 14\n",
      "['pluck'] 14\n",
      "['pluck'] 14\n",
      "['pluck'] 14\n",
      "['pluck'] 14\n",
      "['pluck'] 14\n",
      "['pluck'] 14\n",
      "['pluck'] 14\n",
      "deep thou my do to and yet dwells a \n",
      "gardens why for flowers away eye so survey spent go not to song unwooed nor perjured graces living incertainty ghost upon loves \n",
      "if fever is is \n",
      "of to suppressed buy for should shadow themselves in look lest outward so their \n",
      "\n",
      "so doubting prime whereupon true thief if sum in \n",
      "\n",
      "that \n",
      "to reason four to come for the rich no love cruel without thrusts for is love not come is \n",
      "this this these cheeks self masked and upon gilded captive wasteful ages the of veil then teach not sometime if tables eye than and thou not hath more not my that entitled treason hand every cures my \n",
      "then i one filching uncertain your death silent and angry compile you urge my in thou perjured despised in \n",
      "by that his away have we old unused and not will your where \n",
      "\n",
      "pluck \n",
      "\n",
      "---- Testing with 10 hidden states ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting a model with 31959 free scalar parameters with only 19907 data points will result in a degenerate solution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not'] 13\n",
      "['not'] 13\n",
      "['not'] 13\n",
      "['not'] 13\n",
      "['not'] 13\n",
      "['not'] 13\n",
      "['not'] 13\n",
      "['not'] 13\n",
      "['not'] 13\n",
      "['not'] 13\n",
      "['not'] 13\n",
      "['not'] 13\n",
      "['not'] 13\n",
      "['not'] 13\n",
      "gildst to cost \n",
      "\n",
      "for assure one and those true chose doth the cut \n",
      "lords thy if sweet grieve \n",
      "to mine perfumes of know upon naming \n",
      "longer my remove sorrow truth asleep pilgrimage the when pleasure the far who seek \n",
      "looking beauty if farthest more \n",
      "one \n",
      "the help and love true poor shame every thee no truth with \n",
      "view brow believe painting to do to will \n",
      "thee loves rain bright vex scanted how thou at thou heart an or rarities mine praise and thy summers \n",
      "see \n",
      "not \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num_hidden_states in [2, 5, 10]:\n",
    "    print(\"---- Testing with %i hidden states ----\" % num_hidden_states)\n",
    "    time.sleep(1) # This is here to make sure the warnings print where you expect them\n",
    "    model = wherefore_art_thou_Romeo(num_hidden_states)\n",
    "    serenade_me_oh_sonneteer(model, feat_library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['slandering', 'show', 'her', 'will', 'meet', 'parts', 'day']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def wherefore_art_thou_Romeo(num_hidden_states):\n",
    "    \"\"\" Returns a hmm model trained on Shakespeare's sonnets\"\"\"\n",
    "    np.random.seed(42)\n",
    "    model = hmm.MultinomialHMM(n_components=num_hidden_states)\n",
    "    model = model.fit(sequences, lengths)\n",
    "    return model\n",
    "\n",
    "def get_syllables(word):\n",
    "    return 0\n",
    "\n",
    "def serenade_me_oh_sonneteer(model, feat_library):\n",
    "    new_seq, new_hidden_states = model.sample(300) # Words after \\end will be ignored\n",
    "    \n",
    "    # find first end line or end poem word\n",
    "    end_line = min(new_seq == )\n",
    "    new_sonnet = utils.sequence_to_sonnet(new_seq, feat_library)\n",
    "    line_start = 0\n",
    "    for line in range(14):\n",
    "        syllable_count = 0\n",
    "        word_count = line_start\n",
    "        for word in new_sonnet:\n",
    "            word_count += 1\n",
    "            if word == '\\n':\n",
    "                break\n",
    "            if word == '\\end':\n",
    "                break\n",
    "            syllable_count += get_syllables(word)\n",
    "        print(word, word_count)\n",
    "    utils.print_sonnet(new_sonnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Testing with 10 hidden states ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting a model with 31959 free scalar parameters with only 19907 data points will result in a degenerate solution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gildst to cost \n",
      "\n",
      "for assure one and those true chose doth the cut \n",
      "lords thy if sweet grieve \n",
      "to mine perfumes of know upon naming \n",
      "longer my remove sorrow truth asleep pilgrimage the when pleasure the far who seek \n",
      "looking beauty if farthest more \n",
      "one \n",
      "the help and love true poor shame every thee no truth with \n",
      "view brow believe painting to do to will \n",
      "thee loves rain bright vex scanted how thou at thou heart an or rarities mine praise and thy summers \n",
      "see \n",
      "not \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"---- Testing with %i hidden states ----\" % num_hidden_states)\n",
    "time.sleep(1) # This is here to make sure the warnings print where you expect them\n",
    "model = wherefore_art_thou_Romeo(num_hidden_states)\n",
    "new_seq, new_hidden_states = model.sample(300) # Words after \\end will be ignored\n",
    "new_sonnet = utils.sequence_to_sonnet(new_seq, feat_library)\n",
    "utils.print_sonnet(new_sonnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 301    0 1583  154    0   39  958 1163   17  541 2977  136  321   76\n",
      "    0    0 1546  159 1815 1999  580   78  467    8  227  615  634 2572\n",
      "   58    0    0 1865  291    1 1559 3182  580   70   43   45   17 3170\n",
      "  159   70 1116   70  526   78   70   58]\n",
      "[3 9 5 9 0 5 1 7 1 8 8 8 3 6 7 7 5 0 1 8 8 2 5 8 1 1 6 0 0 6 0 5 6 3 0 0 1\n",
      " 9 7 3 8 2 3 9 3 3 4 0 3 6]\n",
      "2 9 [301   0]\n",
      "5 0 [1583  154    0]\n"
     ]
    }
   ],
   "source": [
    "test_seq, test_hidden_states = model.sample(50) # Words after \\end will be ignored\n",
    "start_new_line = 0\n",
    "print(test_seq[start_new_line:,0])\n",
    "print(test_hidden_states)\n",
    "for i in range(2):\n",
    "    start_old_line = start_new_line\n",
    "    start_new_line = np.asarray(test_seq[start_new_line:,0] == 0).nonzero()[0][0] + start_new_line + 1\n",
    "    test_end_state = test_hidden_states[start_new_line - 1]\n",
    "    print(start_new_line, test_end_state, test_seq[start_old_line:start_new_line,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "1 [['let']]\n",
      "9 [['even', 'thee', 'such', 'that', 'yet', 'have', 'heaven', 'scandal', 'and']]\n",
      "12 [['in', 'heartinflaming', 'not', 'in', 'woe', 'in', 'best', 'be', 'in', 'and', 'not', 'in']]\n",
      "19 [['yet', 'not', 'your', 'doth', 'being', 'swiftfooted', 'hath', 'at', 'not', 'or', 'defence', 'spirit', 'it', 'must', 'was', 'true', 'such', 'the', 'say']]\n",
      "2 [['let', 'when']]\n",
      "3 [['or', 'doth', 'your']]\n",
      "5 [['so', 'near', 'have', 'thou', 'eyes']]\n",
      "8 [['my', ',', 'why', 'mine', 'that', 'were', 'summers', 'control']]\n",
      "9 [['my', 'contains', 'less', 'to', 'loves', 'do', 'speaking', 'rest', 'but']]\n",
      "1 [['feelst']]\n",
      "2 [['not', 'o']]\n",
      "1 [['thus']]\n",
      "1 [['thy']]\n",
      "9 [['flattery', 'thy', 'bent', 'action', 'thou', 'pleasure', 'too', 'the', 'have']]\n",
      "7 [['do', 'her', 'be', 'in', 'doth', 'sum', 'and']]\n",
      "2 [['my', 'youth']]\n",
      "3 [['true', 'hear', 'is']]\n",
      "1 [['why']]\n",
      "5 [['foot', 'my', 'thing', 'public', 'too']]\n",
      "10 [['line', 'fair', 'heals', 'behold', 'hearsay', 'no', 'temptation', 'farthest', 'world', 'at']]\n",
      "3 [['may', 'which', 'that']]\n",
      "4 [['do', 'in', 'pipe', 'doth']]\n",
      "10 [['doubt', 'and', 'thou', 'my', 'comfort', 'way', 'your', 'thee', 'behold', 'alone']]\n",
      "9 [['can', 'shamefully', 'west', 'love', 'store', 'although', 'precious', 'never', 'the']]\n",
      "1 [['that']]\n",
      "9 [['rich', 'a', 'thy', 'mayst', 'which', 'and', 'shall', 'love', 'what']]\n",
      "6 [['o', 'loves', 'you', 'into', 'far', 'me']]\n",
      "1 [['nor']]\n",
      "6 [['every', 'for', 'all', 'cheeks', 'attend', 'to']]\n",
      "3 [['thy', 'into', 'and']]\n",
      "6 [['doth', 'most', 'and', 'not', 'falsespeaking', 'did']]\n",
      "16 [['of', 'princes', 'my', 'world', 'grace', 'live', 'eisel', 'big', 'dear', 'separable', 'say', 'not', 'draw', 'of', 'doting', 'and']]\n",
      "5 [['heart', 'much', 'my', 'which', 'vassal']]\n",
      "2 [['die', 'is']]\n",
      "2 [['those', 'souls']]\n",
      "3 [['own', 'let', 'much']]\n",
      "2 [['in', 'was']]\n",
      "3 [['from', 'thee', 'a']]\n",
      "2 [['a', 'loves']]\n",
      "1 [['born']]\n",
      "1 [['in']]\n",
      "4 [['is', 'the', 'the', 'truetelling']]\n",
      "6 [['thought', 'mind', 'canker', 'anothers', 'ill', 'my']]\n",
      "3 [['new', 'love', 'worthy']]\n",
      "14 [['make', 'mine', 'concord', 'your', 'humble', 'me', 'pleasures', 'will', 'art', 'blame', 'thy', 'the', 'absent', 'in']]\n",
      "3 [['spring', 'and', 'friends']]\n",
      "12 [['deaths', 'rage', 'grave', 'thy', 'the', 'not', 'life', 'a', 'that', 'when', 'my', 'what']]\n",
      "13 [['dost', 'scope', 'one', 'trees', 'make', 'my', 'since', 'foul', 'thou', 'night', 'guilty', 'might', 'memory']]\n",
      "7 [['see', 'man', 'may', 'edge', 'memory', 'the', 'me']]\n",
      "1 [['like']]\n",
      "9 [['the', 'and', 'some', 'correspondence', 'twixt', 'then', 'of', 'gave', 'rich']]\n",
      "6 [['a', 'bootless', 'some', 'that', 'that', 'and']]\n",
      "2 [['sometime', 'complexion']]\n",
      "14 [['hundred', 'her', 'in', 'you', '.', 'turn', 'cruel', 'is', 'better', 'will', 'i', 'addition', 'to', 'than']]\n",
      "16 [['for', 'arts', 'can', 'of', 'enforced', 'is', 'the', 'nor', 'that', 'even', 'why', 'self', 'heart', 'thee', 'silence', 'mortal']]\n",
      "8 [['thine', 'was', 'asked', 'shall', 'thee', 'i', 'the', 'they']]\n",
      "[[ 134]\n",
      " [2947]\n",
      " [ 201]\n",
      " [ 132]\n",
      " [   8]\n",
      " [ 116]\n",
      " [ 278]\n",
      " [1716]\n",
      " [   0]\n",
      " [  31]\n",
      " [ 290]\n",
      " [ 108]\n",
      " [  86]\n",
      " [  82]\n",
      " [ 490]\n",
      " [  17]\n",
      " [ 294]\n",
      " [   0]]\n"
     ]
    }
   ],
   "source": [
    "seq = np.empty((0,1),int)\n",
    "start_new_line = 0\n",
    "for i in range(2):\n",
    "    num_words = 0\n",
    "    while num_words != 8:\n",
    "        test_seq, test_states = model.sample(n_samples=20)\n",
    "        try:\n",
    "            end_line = np.asarray(test_seq[start_new_line:,0] == 0).nonzero()[0][0]\n",
    "        except:\n",
    "            continue\n",
    "        test_seq = test_seq[:end_line+1]\n",
    "        test_line = utils.sequence_to_sonnet(test_seq, feat_library)\n",
    "        num_words = end_line\n",
    "        print(num_words, test_line)\n",
    "    seq = np.vstack((seq, test_seq[:end_line+1]))\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your should with night as keep with back \n",
      "where his of thee churl pace yet him \n",
      "\n"
     ]
    }
   ],
   "source": [
    "utils.print_sonnet(utils.sequence_to_sonnet(seq, feat_library))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_syllable_dict(datafile = './data/Syllable_dictionary.txt'):\n",
    "    with open(datafile, 'r') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # split file into lines and words\n",
    "    lines = [tknzr.tokenize(line) for line in text.split('\\n') if line.split()]\n",
    "\n",
    "    # Strip punctuation\n",
    "    for i, line in enumerate(lines):\n",
    "        for j, _ in enumerate(line):\n",
    "            punc = \"'\"\n",
    "            for punc in string.punctuation:\n",
    "                lines[i][j] = lines[i][j].replace(punc, \"\")\n",
    "            if len(lines[i][j]) == 0:\n",
    "                del lines[i][j]\n",
    "\n",
    "    # split up each sonnet, remove line denoting sonnet number\n",
    "    sonnets = []\n",
    "    for i, line in enumerate(lines):\n",
    "        if line[0].isdigit():\n",
    "            sonnet_number = int(line[0]) - 1\n",
    "            sonnets.append([])\n",
    "        else:\n",
    "            sonnets[sonnet_number].append(line)\n",
    "\n",
    "    # convert words to lower case\n",
    "    for i, sonnet in enumerate(sonnets):\n",
    "        for j, line in enumerate(sonnet):\n",
    "            for k, word in enumerate(line):\n",
    "                sonnets[i][j][k] = word.lower()\n",
    "\n",
    "    return sonnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'gainst\", '1\\n']\n",
      "[\"'greeing\", 'E1', '2\\n']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-134-2213785a0f62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msyllables\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mpunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "datafile = './data/Syllable_dictionary.txt'\n",
    "syllable_dict = {} \n",
    "with open(datafile) as f:\n",
    "    for line in f:\n",
    "        l = line.split(' ')\n",
    "        print(l)\n",
    "        (word, syllables) = l\n",
    "        punc = \"'\"\n",
    "        word = word.replace(punc, \"\")\n",
    "        # Check if word is already in dictionary\n",
    "        if not word in syllable_dict.keys():\n",
    "            syllable_dict[word] = syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('CS155': conda)",
   "language": "python",
   "name": "python36764bitcs155conda196b6158d68141a1a0cb46f93387a3ad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
