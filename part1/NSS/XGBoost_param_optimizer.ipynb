{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "\n",
    "%load_ext watermark\n",
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "df_train_y = pd.read_csv(\"../CS155_PROJECT1/Data/caltech-cs155-2020/train.csv\", index_col=0, usecols = [0,27])\n",
    "df_train = pd.read_csv(\"../CS155_PROJECT1/Data/caltech-cs155-2020/train.csv\", index_col=0, usecols = lambda column : column not in[\"y\"])\n",
    "df_train_full= pd.read_csv(\"../CS155_PROJECT1/Data/caltech-cs155-2020/train.csv\", index_col=0)\n",
    "df_test = pd.read_csv(\"../CS155_PROJECT1/Data/caltech-cs155-2020/test.csv\", index_col=0)\n",
    "\n",
    "#splitting into training and validation sets \n",
    "X_train, X_validate, y_train, y_validate = sklearn.model_selection.train_test_split(df_train, df_train_y, test_size=0.2, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\t\t#loading data into xgb format\n",
    "dtrain = xgb.DMatrix(X_train, label = y_train)\n",
    "dvalidate =xgb.DMatrix(X_validate, label = y_validate)\n",
    "dtest = xgb.DMatrix(df_test)\n",
    "dtrainfull = xgb.DMatrix(df_train, label = df_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':5,\n",
    "    'min_child_weight': 0,\n",
    "    'eta':.01,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    'gamma' : 0,\n",
    "    # Other parameters\n",
    "    'objective':'binary:logistic',\n",
    "    'eval_metric':'auc',\n",
    "}\n",
    "\n",
    "#define the eval metrics\n",
    "evals = [(dtrain, 'train'), (dvalidate, 'validate')]\n",
    "\n",
    "#high number of boosting rounds to allow the model to go to completion\n",
    "num_boost_round = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a model with the initial parameters as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.train(params, dtrain, num_boost_round, evals=evals, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train all combinatorially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight, eta, subsample, colsample, gamma)\n",
    "    for max_depth in range(3,8)\n",
    "    for min_child_weight in range(0,2)\n",
    "    for eta in (0.2, .1, .05, .01)\n",
    "    for subsample in [i/10. for i in range(8,11)]\n",
    "    for colsample in [i/10. for i in range(8,11)]\n",
    "    for gamma in (.1, 0.0)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All combinations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define initial best params and auc\n",
    "max_auc = float(0)\n",
    "best_params = None\n",
    "for max_depth, min_child_weight, eta, subsample, colsample, gamma in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}, eta={}, subsample={}, colsample={}, gamma={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight,\n",
    "                             eta,\n",
    "                             subsample,\n",
    "                             colsample,\n",
    "                             gamma))\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    params['eta'] = eta\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "    params['gamma'] = gamma\n",
    "    \n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=300,\n",
    "        seed=28,\n",
    "        nfold=10,\n",
    "        metrics={'auc'},\n",
    "        early_stopping_rounds=7\t\n",
    "    )\n",
    "    \n",
    "    # Update best AUC\n",
    "    mean_auc = cv_results['test-auc-mean'].max()\n",
    "    boost_rounds = cv_results['test-auc-mean'].idxmax()\n",
    "    print(\"\\tAUC {} for {} rounds\". format(mean_auc, boost_rounds))\n",
    "    if mean_auc > max_auc:\n",
    "        max_auc = mean_auc\n",
    "        best_params = (max_depth,min_child_weight,eta,subsample,colsample,gamma)\n",
    "print(\"Best params: max_depth={}, min_child_weight={}, eta={}, subsample={}, colsample={}, gamma={} AUC: {}\".format(best_params[0], best_params[1], best_params[2], best_params[3], best_params[4], best_params[5], max_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the parameters\n",
    "params['max_depth'] = best_params[0]\n",
    "params['min_child_weight'] = best_params[1]\n",
    "params['eta'] = best_params[2]\n",
    "params['subsample'] = best_params[3]\n",
    "params['colsample_bytree'] = best_params[4]\n",
    "params['gamma'] = best_params[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a model with the new params and exactly the right number of iterations to see its performance on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round = model.best_iteration + 1\n",
    "\n",
    "best_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=evals\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is the above AUC score correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict on validation set\n",
    "ypred = best_model.predict(dvalidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate AUC on validation set\n",
    "roc = sklearn.metrics.roc_auc_score(y_validate, ypred)\n",
    "print(\"AUC: %.4f%% \" % (roc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict on test set\n",
    "predictions = best_model.predict(dtest)\n",
    "\n",
    "# Kaggle needs the submission to have a certain format;\n",
    "submission = pd.DataFrame({ 'id': df_test.index,\n",
    "                            'Predicted': predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>592380</td>\n",
       "      <td>0.528990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>592381</td>\n",
       "      <td>0.342812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>592382</td>\n",
       "      <td>0.395533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>592383</td>\n",
       "      <td>0.577469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>592384</td>\n",
       "      <td>0.345996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  Predicted\n",
       "0  592380   0.528990\n",
       "1  592381   0.342812\n",
       "2  592382   0.395533\n",
       "3  592383   0.577469\n",
       "4  592384   0.345996"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#is the format correct?\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"XGboost_model2_combinatorial_optimizer_submission1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model in case we want to use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save_model(\"best_model.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
