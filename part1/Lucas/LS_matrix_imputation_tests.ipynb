{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tqdm import tqdm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sample_submission.csv', 'test.csv', 'train.csv'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = ZipFile(\"../caltech-cs155-2020.zip\")\n",
    "\n",
    "dfs = {text_file.filename: pd.read_csv(z.open(text_file.filename))\n",
    "       for text_file in z.infolist()\n",
    "       if text_file.filename.endswith('.csv')}\n",
    "dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>last_price</th>\n",
       "      <th>mid</th>\n",
       "      <th>opened_position_qty</th>\n",
       "      <th>closed_position_qty</th>\n",
       "      <th>transacted_qty</th>\n",
       "      <th>d_open_interest</th>\n",
       "      <th>bid1</th>\n",
       "      <th>bid2</th>\n",
       "      <th>bid3</th>\n",
       "      <th>...</th>\n",
       "      <th>bid2vol</th>\n",
       "      <th>bid3vol</th>\n",
       "      <th>bid4vol</th>\n",
       "      <th>bid5vol</th>\n",
       "      <th>ask1vol</th>\n",
       "      <th>ask2vol</th>\n",
       "      <th>ask3vol</th>\n",
       "      <th>ask4vol</th>\n",
       "      <th>ask5vol</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3842.4</td>\n",
       "      <td>3842.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3842.4</td>\n",
       "      <td>3842.0</td>\n",
       "      <td>3841.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3842.8</td>\n",
       "      <td>3843.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>-43</td>\n",
       "      <td>3843.0</td>\n",
       "      <td>3842.8</td>\n",
       "      <td>3842.4</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3844.0</td>\n",
       "      <td>3844.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>-69</td>\n",
       "      <td>3843.8</td>\n",
       "      <td>3843.6</td>\n",
       "      <td>3843.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3843.8</td>\n",
       "      <td>3843.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-30</td>\n",
       "      <td>3843.0</td>\n",
       "      <td>3842.8</td>\n",
       "      <td>3842.4</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3843.2</td>\n",
       "      <td>3843.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-35</td>\n",
       "      <td>3842.8</td>\n",
       "      <td>3842.4</td>\n",
       "      <td>3842.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  last_price     mid  opened_position_qty   closed_position_qty  \\\n",
       "0   0      3842.4  3842.6                   NaN                  NaN   \n",
       "1   1      3842.8  3843.4                   6.0                 49.0   \n",
       "2   2      3844.0  3844.3                   7.0                 77.0   \n",
       "3   3      3843.8  3843.4                   3.0                 34.0   \n",
       "4   4      3843.2  3843.1                   3.0                 38.0   \n",
       "\n",
       "   transacted_qty  d_open_interest    bid1    bid2    bid3  ...  bid2vol  \\\n",
       "0           103.0                0  3842.4  3842.0  3841.8  ...        1   \n",
       "1            55.0              -43  3843.0  3842.8  3842.4  ...        6   \n",
       "2            84.0              -69  3843.8  3843.6  3843.2  ...        1   \n",
       "3            37.0              -30  3843.0  3842.8  3842.4  ...       13   \n",
       "4            41.0              -35  3842.8  3842.4  3842.0  ...       12   \n",
       "\n",
       "   bid3vol  bid4vol  bid5vol  ask1vol  ask2vol  ask3vol  ask4vol  ask5vol  y  \n",
       "0        6       14        6        6        1        1       10        2  1  \n",
       "1       11        1        6        1        4        4        1       13  0  \n",
       "2        4       21       12        1       16       10        4        9  0  \n",
       "3       12        2        4        2        7        1        2       11  1  \n",
       "4        2        2        4        1        3        1       11       15  1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = dfs['train.csv']\n",
    "df_test = dfs['test.csv']\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterativeImputer(add_indicator=False, estimator=None,\n",
       "                 imputation_order='ascending', initial_strategy='mean',\n",
       "                 max_iter=100, max_value=None, min_value=None,\n",
       "                 missing_values=nan, n_nearest_features=None, random_state=0,\n",
       "                 sample_posterior=False, skip_complete=False, tol=0.001,\n",
       "                 verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if the imputer works in the first place\n",
    "array_train = df_train.to_numpy()\n",
    "imp = IterativeImputer(max_iter=100, random_state=0)\n",
    "imp.fit(array_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = imp.transform(array_train)\n",
    "# Seems to work well. Let's do some tests whether it performs well too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000e+00, 3.84280e+03, 3.84340e+03, ..., 1.00000e+00,\n",
       "        1.30000e+01, 0.00000e+00],\n",
       "       [2.00000e+00, 3.84400e+03, 3.84430e+03, ..., 4.00000e+00,\n",
       "        9.00000e+00, 0.00000e+00],\n",
       "       [3.00000e+00, 3.84380e+03, 3.84340e+03, ..., 2.00000e+00,\n",
       "        1.10000e+01, 1.00000e+00],\n",
       "       ...,\n",
       "       [5.92374e+05, 4.10940e+03, 4.10980e+03, ..., 1.00000e+01,\n",
       "        7.00000e+00, 1.00000e+00],\n",
       "       [5.92375e+05, 4.11020e+03, 4.11030e+03, ..., 7.00000e+00,\n",
       "        7.00000e+00, 1.00000e+00],\n",
       "       [5.92376e+05, 4.10940e+03, 4.11050e+03, ..., 7.00000e+00,\n",
       "        5.00000e+00, 0.00000e+00]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all rows with NaN to have it cleaner \n",
    "array_no_NaN = array_train[~np.isnan(array_train).any(axis = 1)]\n",
    "array_no_NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_NaN(array):\n",
    "    row, col = np.random.randint(len(array_no_NaN)), np.random.randint(28)\n",
    "    value = array[row, col]\n",
    "    array[row, col] = np.NaN\n",
    "    value_dict = {(row, col) : value}\n",
    "    \n",
    "    return array, value_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 49466.97it/s]\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "NaN_true_dict = {}\n",
    "for i in tqdm(range(N)):\n",
    "    out = produce_NaN(array_no_NaN)\n",
    "    NaN_true_dict.update(out[1])\n",
    "    array_no_NaN = out[0]\n",
    "\n",
    "key_list = list(NaN_true_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.fit(array_no_NaN)\n",
    "test = imp.transform(array_no_NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss_array = np.empty(N)\n",
    "\n",
    "for j, i in enumerate(key_list):\n",
    "    value = test[i[0]][i[1]]\n",
    "    loss = (NaN_true_dict[i] - value)**2\n",
    "    Loss_array[j] = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.46772518696692\n"
     ]
    }
   ],
   "source": [
    "mse = np.average(Loss_array)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this seems pretty bad, but we can still see how it performs for predictions. There are a few more things we can try:\n",
    "\n",
    "- k-nearest neighbor imputation on the full data\n",
    "- k-nearest on each feature vector\n",
    "- normalized feature vector matrix imputation\n",
    "- matrix imputation on single feature vectors\n",
    "- simple imputation with the mean from the feature vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize feature vectors\n",
    "\n",
    "norm_train = np.empty((len(array_no_NaN), 28))\n",
    "\n",
    "for i in range(28):\n",
    "    col_max = max(array_no_NaN[:, i])\n",
    "    col_min = min(array_no_NaN[:, i])\n",
    "    norm_train[:, i] = (array_no_NaN[:, i] - col_min) / (col_max - col_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 50105.17it/s]\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "NaN_norm_dict = {}\n",
    "for i in tqdm(range(N)):\n",
    "    out = produce_NaN(norm_train)\n",
    "    NaN_norm_dict.update(out[1])\n",
    "    norm_train = out[0]\n",
    "\n",
    "key_list_norm = list(NaN_norm_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007850902672973293\n"
     ]
    }
   ],
   "source": [
    "imp.fit(norm_train)\n",
    "test = imp.transform(norm_train)\n",
    "\n",
    "Loss_array = np.empty(N)\n",
    "\n",
    "for j, i in enumerate(key_list_norm):\n",
    "    value = test[i[0]][i[1]]\n",
    "    loss = (NaN_norm_dict[i] - value)**2\n",
    "    Loss_array[j] = loss\n",
    "    \n",
    "mse = np.average(Loss_array)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks pretty good! But let's try some other one's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets check where the NaNs are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "array_train = df_train.to_numpy()\n",
    "\n",
    "for i in range(28):\n",
    "    feature = array_train[:,i]\n",
    "    print(np.isnan(feature).any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       ...,\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(np.isnan(array_train[:,3])) == np.argwhere(np.isnan(array_train[:,4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix imputation at only one feature vector\n",
    "N.B.: we found that NaN's only occur at feature 3 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_3 = copy.deepcopy(array_train[:,3])\n",
    "vector_4 = copy.deepcopy(array_train[:,4])\n",
    "\n",
    "# No more NaN's\n",
    "vector_3 = vector_3[np.logical_not(np.isnan(vector_3))]\n",
    "vector_4 = vector_4[np.logical_not(np.isnan(vector_4))]\n",
    "\n",
    "#Normalize vector\n",
    "col_max_3 = max(vector_3)\n",
    "col_min_3 = min(vector_3)\n",
    "vector_3 = (vector_3 - col_min_3)/(col_max_3 - col_min_3)\n",
    "\n",
    "col_max_4 = max(vector_4)\n",
    "col_min_4 = min(vector_4)\n",
    "vector_4 = (vector_4 - col_min_4)/(col_max_4 - col_min_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_3_dict = {}\n",
    "vector_4_dict = {}\n",
    "indices = np.empty(int(len(vector_3)/10))\n",
    "\n",
    "for i in range(int(len(vector_3)/10)):\n",
    "    index = np.random.randint(len(vector_3))\n",
    "    indices[i] = index\n",
    "    \n",
    "    value_3 = vector_3[index]\n",
    "    temp_3 = {index : value_3}\n",
    "    vector_3_dict.update(temp_3)\n",
    "    \n",
    "    value_4 = vector_4[index]\n",
    "    temp_4 = {index : value_4}\n",
    "    vector_4_dict.update(temp_4)\n",
    "    \n",
    "for j in indices:\n",
    "    vector_3[int(j)] = np.NaN\n",
    "    vector_4[int(j)] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_3_keys = list(vector_3_dict.keys())\n",
    "vector_4_keys = list(vector_4_dict.keys())\n",
    "\n",
    "vector_3 = np.reshape(vector_3, (-1,1))\n",
    "vector_4 = np.reshape(vector_4, (-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00046725852362711234\n"
     ]
    }
   ],
   "source": [
    "imp.fit(vector_3)\n",
    "test_3 = imp.transform(vector_3)\n",
    "test_3 = test_3.flatten()\n",
    "\n",
    "Loss_array = []\n",
    "\n",
    "for i in vector_3_keys:\n",
    "    value = test_3[i]\n",
    "    loss = (vector_3_dict[i] - value)**2\n",
    "    Loss_array.append(loss)\n",
    "    \n",
    "imp.fit(vector_4)\n",
    "test_4 = imp.transform(vector_4)\n",
    "test_4 = test_4.flatten()\n",
    "    \n",
    "for j in vector_4_keys:\n",
    "    value = test_4[j]\n",
    "    loss = (vector_4_dict[j] - value)**2\n",
    "    Loss_array.append(loss)\n",
    "    \n",
    "mse = np.average(Loss_array)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Imputer unfortunately does not work, we get a memory error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_train = df_train.to_numpy()\n",
    "array_simple_mean = copy.deepcopy(array_train[:,3:5])\n",
    "array_simple_median = copy.deepcopy(array_train[:,3:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set NaN's to be the mean or median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_median = SimpleImputer(missing_values = np.NaN, strategy = 'median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean.fit(array_simple_mean)\n",
    "transformed_mean_array = imp_mean.transform(array_simple_mean)\n",
    "\n",
    "imp_median.fit(array_simple_median)\n",
    "transformed_median_array = imp_mean.transform(array_simple_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.40058344,  1.96427653],\n",
       "       [ 6.        , 49.        ],\n",
       "       [ 7.        , 77.        ],\n",
       "       ...,\n",
       "       [ 1.40058344,  1.96427653],\n",
       "       [ 1.40058344,  1.96427653],\n",
       "       [ 1.40058344,  1.96427653]])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_mean_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.40058344,  1.96427653],\n",
       "       [ 6.        , 49.        ],\n",
       "       [ 7.        , 77.        ],\n",
       "       ...,\n",
       "       [ 1.40058344,  1.96427653],\n",
       "       [ 1.40058344,  1.96427653],\n",
       "       [ 1.40058344,  1.96427653]])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_median_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_no_NaN = array_train[~np.isnan(array_train).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_3 = copy.deepcopy(simple_no_NaN[:,3])\n",
    "vector_4 = copy.deepcopy(simple_no_NaN[:,4])\n",
    "\n",
    "#Normalize vector\n",
    "col_max_3 = max(vector_3)\n",
    "col_min_3 = min(vector_3)\n",
    "vector_3 = (vector_3 - col_min_3)/(col_max_3 - col_min_3)\n",
    "\n",
    "col_max_4 = max(vector_4)\n",
    "col_min_4 = min(vector_4)\n",
    "vector_4 = (vector_4 - col_min_4)/(col_max_4 - col_min_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_3_dict = {}\n",
    "vector_4_dict = {}\n",
    "indices = np.empty(int(len(vector_3)/10))\n",
    "\n",
    "for i in range(int(len(vector_3)/10)):\n",
    "    index = np.random.randint(len(vector_3))\n",
    "    indices[i] = index\n",
    "    \n",
    "    value_3 = vector_3[index]\n",
    "    temp_3 = {index : value_3}\n",
    "    vector_3_dict.update(temp_3)\n",
    "    \n",
    "    value_4 = vector_4[index]\n",
    "    temp_4 = {index : value_4}\n",
    "    vector_4_dict.update(temp_4)\n",
    "    \n",
    "for j in indices:\n",
    "    vector_3[int(j)] = np.NaN\n",
    "    vector_4[int(j)] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_3_keys = list(vector_3_dict.keys())\n",
    "vector_4_keys = list(vector_4_dict.keys())\n",
    "\n",
    "vector_3 = np.reshape(vector_3, (-1,1))\n",
    "vector_4 = np.reshape(vector_4, (-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004925922832461261\n"
     ]
    }
   ],
   "source": [
    "imp_mean.fit(vector_3)\n",
    "test_3 = imp_mean.transform(vector_3)\n",
    "test_3 = test_3.flatten()\n",
    "\n",
    "Loss_array = []\n",
    "\n",
    "for i in vector_3_keys:\n",
    "    value = test_3[i]\n",
    "    loss = (vector_3_dict[i] - value)**2\n",
    "    Loss_array.append(loss)\n",
    "    \n",
    "imp_mean.fit(vector_4)\n",
    "test_4 = imp_mean.transform(vector_4)\n",
    "test_4 = test_4.flatten()\n",
    "    \n",
    "for j in vector_4_keys:\n",
    "    value = test_4[j]\n",
    "    loss = (vector_4_dict[j] - value)**2\n",
    "    Loss_array.append(loss)\n",
    "    \n",
    "mse = np.average(Loss_array)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009275416206993202"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_4[49497]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009275416206993204"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(test_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004885148549834864\n"
     ]
    }
   ],
   "source": [
    "imp_median.fit(vector_3)\n",
    "test_3 = imp_median.transform(vector_3)\n",
    "test_3 = test_3.flatten()\n",
    "\n",
    "Loss_array = []\n",
    "\n",
    "for i in vector_3_keys:\n",
    "    value = test_3[i]\n",
    "    loss = (vector_3_dict[i] - value)**2\n",
    "    Loss_array.append(loss)\n",
    "    \n",
    "imp_median.fit(vector_4)\n",
    "test_4 = imp_median.transform(vector_4)\n",
    "test_4 = test_4.flatten()\n",
    "    \n",
    "for j in vector_4_keys:\n",
    "    value = test_4[j]\n",
    "    loss = (vector_4_dict[j] - value)**2\n",
    "    Loss_array.append(loss)\n",
    "    \n",
    "mse = np.average(Loss_array)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0047169811320754715"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_4[300239]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0047169811320754715"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(test_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
